{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e386daf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-2d804c25904b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Binarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, RepeatedStratifiedKFold, train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, RFE\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing\n",
    "from hyperopt import tpe\n",
    "\n",
    "import neptune.new as neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9cb238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47440c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/julia.grzegorowska/ml-project/e/MLPROJ-15\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "run = neptune.init(\n",
    "    project=\"julia.grzegorowska/ml-project\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI0YzMwMDM2OC04YzdlLTQxOGEtYmEzYi0xZTA3ZmQzMjlkNzIifQ==\",\n",
    ")\n",
    "\n",
    "params = {\n",
    "    \"optimizer\": \"Julia\"\n",
    "}\n",
    "run[\"parameters\"] = params\n",
    "\n",
    "\n",
    "def send_data_neptune(data, plot_name):\n",
    "    for epoch in range(0, len(data)):\n",
    "      run[plot_name].log(data[epoch])\n",
    "\n",
    "def single_record(record, record_name):\n",
    "    run[record_name] = record\n",
    "\n",
    "def stop_run():\n",
    "    run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da8de10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d42b574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = np.random.seed(147)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c85e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load() -> list:\n",
    "\n",
    "    train_data = pd.read_csv(\"data/train_data.csv\", header=None)\n",
    "    test_data = pd.read_csv(\"data/test_data.csv\", header=None)\n",
    "    train_labels = pd.read_csv(\"data/train_labels.csv\", header=None)\n",
    "    \n",
    "\n",
    "    ## Save to neptune train labels\n",
    "    a = train_labels.values\n",
    "    tmp = []\n",
    "    for i in range(0, len(a)):\n",
    "      tmp.append(int(a[i]))\n",
    "\n",
    "    send_data_neptune(tmp, \"train_labels\")\n",
    "\n",
    "\n",
    "    return [train_data, test_data, train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81dee167",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels = data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9aec1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_ravel = train_labels.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a954199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_standard_minmax(X_1, X_2: pd.DataFrame) -> np.array:\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "    (\"std\", StandardScaler()),\n",
    "    (\"minmax\", MinMaxScaler())])\n",
    "    \n",
    "    train_std_minmax = pipeline.fit_transform(X_1)\n",
    "    test_std_minmax = pipeline.fit_transform(X_2)\n",
    "    \n",
    "    return [train_std_minmax, train_std_minmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "969a8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_std_minmax, test_std_minmax = pipeline_standard_minmax(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f389da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=int(len(train_data.columns)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43f5e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kbest_select(x_1: np.array, x_2: np.array, y_1: np.array, n_of_kbest: int) -> list:\n",
    "    print(f\"Shape before: {x_1.shape}\\n\")\n",
    "    \n",
    "    test = SelectKBest(score_func=f_classif, k=n_of_kbest)\n",
    "    fit = test.fit(x_1, y_1)\n",
    "    features_first = fit.transform(x_1)\n",
    "    features_second = fit.transform(x_2)\n",
    "    \n",
    "    scores = fit.scores_\n",
    "    score_df = pd.DataFrame(scores, columns=[\"Scores\"])\n",
    "    print(f\"Min score: {min(score_df.Scores)}, max score: {max(score_df.Scores)}, mean score: {np.mean(score_df.Scores)}\\n\")    \n",
    "    print(f\"Shape after: {features_first.shape}\\n\")\n",
    "    \n",
    "    score_df.drop(score_df[score_df.Scores < 1].index, inplace=True)\n",
    "    l = len(score_df)\n",
    "\n",
    "    ## Save to Neptune\n",
    "    single_record(min(score_df.Scores), 'kbest_select_min_score')\n",
    "    single_record(max(score_df.Scores), 'kbest_select_max_score')\n",
    "    single_record(np.mean(score_df.Scores), 'kbest_select_mean_score')\n",
    "    \n",
    "    if l != n_of_kbest:\n",
    "        return kbest_select(train_std_minmax, test_std_minmax, train_labels_ravel, l)\n",
    "    else:\n",
    "        return [features_first, features_second]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a655ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (3750, 10000)\n",
      "\n",
      "Min score: 1.7567042700994732e-09, max score: 17.321255892491074, mean score: 1.000380011727585\n",
      "\n",
      "Shape after: (3750, 3333)\n",
      "\n",
      "Shape before: (3750, 10000)\n",
      "\n",
      "Min score: 1.7567042700994732e-09, max score: 17.321255892491074, mean score: 1.000380011727585\n",
      "\n",
      "Shape after: (3750, 3177)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kbest_train, kbest_test = kbest_select(train_std_minmax, test_std_minmax, train_labels_ravel,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60cea686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_select(x_1, x_2: np.array) -> np.array:\n",
    "    \n",
    "    print(f\"Shape before transforamtion: {x_1.shape}\\n\")\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "    pca = PCA(n_components=100, random_state=seed)\n",
    "    fit = pca.fit(x_1)\n",
    "    features_first = fit.transform(x_1)\n",
    "    features_second = fit.transform(x_2)\n",
    "    \n",
    "    print(f\"Explained Variance: \\n{fit.explained_variance_ratio_}\\n\")\n",
    "    print(f\"Shape after transormation: {features_first.shape}\")\n",
    "\n",
    "    send_data_neptune(fit.explained_variance_ratio_, \"explained_variance_ration\")\n",
    "    \n",
    "    return [features_first, features_second]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e9e5e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before transforamtion: (3750, 3177)\n",
      "\n",
      "Explained Variance: \n",
      "[0.00119912 0.00115652 0.00114973 0.00114476 0.00114238 0.00113942\n",
      " 0.00113693 0.00112986 0.00112779 0.00112082 0.0011182  0.00111573\n",
      " 0.00111269 0.00111089 0.00110794 0.00110688 0.00109969 0.00109535\n",
      " 0.00109378 0.00109121 0.00108836 0.00108419 0.00108334 0.00108155\n",
      " 0.00107696 0.0010749  0.00107404 0.0010718  0.00106935 0.001067\n",
      " 0.00106293 0.00106    0.00105852 0.00105635 0.0010534  0.00105165\n",
      " 0.00105014 0.00104801 0.00104623 0.00104508 0.00104468 0.00103807\n",
      " 0.00103631 0.00103511 0.00103434 0.00102916 0.0010273  0.001026\n",
      " 0.00102531 0.00102077 0.00101904 0.00101632 0.00101535 0.00101456\n",
      " 0.0010118  0.00100976 0.00100892 0.0010047  0.00100352 0.00099885\n",
      " 0.00099852 0.00099734 0.00099596 0.00099475 0.00099243 0.00099103\n",
      " 0.00098759 0.00098466 0.00098348 0.00097789 0.00097721 0.00097503\n",
      " 0.00097383 0.00097047 0.00096941 0.00096651 0.000966   0.00096494\n",
      " 0.00096335 0.00096063 0.00095943 0.00095832 0.00095427 0.0009528\n",
      " 0.00094974 0.00094905 0.00094808 0.00094325 0.00094171 0.00093861\n",
      " 0.00093564 0.00093255 0.00093161 0.00092615 0.00092407 0.00092406\n",
      " 0.00092029 0.00091553 0.00091423 0.00091246]\n",
      "\n",
      "Shape after transormation: (3750, 100)\n"
     ]
    }
   ],
   "source": [
    "pca_train, pca_test = pca_select(kbest_train, kbest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "050b4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_select(X_1, X_2, y_1: np.array) -> np.array:\n",
    "    \n",
    "    print(f\"Shape before transformation: {X_1.shape}\\n\")\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    svc = SVC(kernel=\"linear\", C=1, random_state=seed)\n",
    "    rfe = RFE(estimator=svc, n_features_to_select=5)\n",
    "    fit = rfe.fit(X_1, y_1)\n",
    "    first_features = fit.transform(X_1)\n",
    "    second_features = fit.transform(X_2)\n",
    "    \n",
    "    print(f\"Feature Ranking: \\n{fit.ranking_}\\n\")\n",
    "    print(f\"Shape after: {first_features.shape}\\n\")\n",
    "\n",
    "    send_data_neptune(fit.ranking_, \"fit-ranking\")\n",
    "    \n",
    "    return [first_features, second_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c74f1b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before transformation: (3750, 100)\n",
      "\n",
      "Feature Ranking: \n",
      "[ 1  1  1 48 24 50  1 72 81  7 60 21 19 91  4  6 73 32 22  2 63 18 89  9\n",
      " 65 39 53 64 11 42 12 66 16 40 61 33 77 45 15 87 82 62  1 68 20 23 95 34\n",
      " 74 44 67 47 94 35 56 25 80 86 41 75 49 52 10 83  5 84  8 71 26 31 96 76\n",
      " 69 79 59 55 28 85 29 27 88 90 57 30  3 58 14 13 38 43 37 46 78 36 17 92\n",
      " 70 93 51 54]\n",
      "\n",
      "Shape after: (3750, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfe_train, rfe_test = rfe_select(pca_train, pca_test, train_labels_ravel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ecb57075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(x_1: np.array, y_1: np.array) -> list:\n",
    "    over = RandomOverSampler(sampling_strategy=0.2)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    x_resampled, y_resampled = pipeline.fit_resample(x_1, y_1)\n",
    "\n",
    "    tmp_X = []\n",
    "    for i in range(0, len(x_resampled)):\n",
    "        for j in range(0, len(x_resampled[i])):\n",
    "            tmp_X.append(x_resampled[i][j])\n",
    "\n",
    "    send_data_neptune(tmp_X, \"X-resampled\")\n",
    "    send_data_neptune(y_resampled, \"y-resampled\")\n",
    "\n",
    "    return [x_resampled, y_resampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f3523d1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomOverSampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-90b4f3168ec8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_sampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfe_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels_ravel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-56-a548e35020b3>\u001b[0m in \u001b[0;36mrandom_sampling\u001b[1;34m(x_1, y_1)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrandom_sampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mover\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0munder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'o'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mover\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'u'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomOverSampler' is not defined"
     ]
    }
   ],
   "source": [
    "x_resampled, y_resampled = random_sampling(rfe_train, train_labels_ravel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0bb6bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(train_x: np.array, test_x: np.array, train_y: np.array) -> None:\n",
    "\n",
    "    np.save('project_data/processed_train_X.npy', train_x)\n",
    "    np.save('project_data/processed_test_X.npy', test_x)\n",
    "    np.save('project_data/processed_train_y.npy', train_y)\n",
    "    \n",
    "    print(\"Saving has been completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "921281eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_resampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-99028e719277>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msave_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfe_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_resampled' is not defined"
     ]
    }
   ],
   "source": [
    "save_data(x_resampled, rfe_test, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66032e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
